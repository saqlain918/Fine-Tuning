{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "946ce79aa8af4282baa013114420ce41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_842a6f4e4df54807bb009899d302b910",
              "IPY_MODEL_968133482ca14ded93f1b0a344536c35",
              "IPY_MODEL_8548cf15f2b447cf82fd291a0c6d911b"
            ],
            "layout": "IPY_MODEL_c196387f3946424fa7970d2e3d2db9e7"
          }
        },
        "842a6f4e4df54807bb009899d302b910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fe756c99ab944a59ecf1dae8701cb79",
            "placeholder": "​",
            "style": "IPY_MODEL_05c008a2e97448d98e4548481eef1ba6",
            "value": "Map: 100%"
          }
        },
        "968133482ca14ded93f1b0a344536c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb5acc7be9c8428989fa224e6549975d",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a91cb8421e1940118d0544b663fed9b1",
            "value": 20
          }
        },
        "8548cf15f2b447cf82fd291a0c6d911b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7fc27645ab243c9bd771661eb291dc1",
            "placeholder": "​",
            "style": "IPY_MODEL_87a0358f2f9a4c57887ee6b5eaa0b905",
            "value": " 20/20 [00:00&lt;00:00, 416.82 examples/s]"
          }
        },
        "c196387f3946424fa7970d2e3d2db9e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fe756c99ab944a59ecf1dae8701cb79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05c008a2e97448d98e4548481eef1ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb5acc7be9c8428989fa224e6549975d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a91cb8421e1940118d0544b663fed9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7fc27645ab243c9bd771661eb291dc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a0358f2f9a4c57887ee6b5eaa0b905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install torch transformers peft datasets gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFmO5wrO1qF_",
        "outputId": "56acad57-d4a5-48ac-b944-6f2aa63040d7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.22.0-py3-none-any.whl (46.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, xxhash, uvicorn, tomlkit, semantic-version, ruff, python-multipart, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, groovy, ffmpy, dill, aiofiles, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, safehttpx, nvidia-cusolver-cu12, gradio-client, fastapi, gradio, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aiofiles-23.2.1 datasets-3.4.1 dill-0.3.8 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.22.0 gradio-client-1.8.0 groovy-0.1.2 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.0 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "946ce79aa8af4282baa013114420ce41",
            "842a6f4e4df54807bb009899d302b910",
            "968133482ca14ded93f1b0a344536c35",
            "8548cf15f2b447cf82fd291a0c6d911b",
            "c196387f3946424fa7970d2e3d2db9e7",
            "4fe756c99ab944a59ecf1dae8701cb79",
            "05c008a2e97448d98e4548481eef1ba6",
            "fb5acc7be9c8428989fa224e6549975d",
            "a91cb8421e1940118d0544b663fed9b1",
            "e7fc27645ab243c9bd771661eb291dc1",
            "87a0358f2f9a4c57887ee6b5eaa0b905"
          ]
        },
        "id": "DK-vI-XA1H2p",
        "outputId": "425d2b10-c552-4b52-b337-73ad8a3d7b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created with 20 examples.\n",
            "GPT-2 model loaded.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "946ce79aa8af4282baa013114420ce41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset tokenized.\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 01:49, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.874800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.170700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.601300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.185700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.434800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.928600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.378800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.052400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.136800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.048400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.747100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.022400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.100500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.817000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.785600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.031800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>2.263800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.764000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.801000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.214700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>2.121700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.370700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.917100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete!\n",
            "Prompt: 8 ÷ 2(2+2) = 1?\n",
            "Output: Incorrect: 8 ÷ 2(2+2) = 1? Correct: Error evaluating expression: Unsupported operation\n",
            "\n",
            "Prompt: 5 + 5 = 20?\n",
            "Raw output from GPT-2 for 5 + 5 = 20?: Incorrect: 5 + 5 = 20? Explanation:  Multiplication error. Explanation: Multiplication error. Explanation: Multiplication error. Explanation: Multiplication error. Explanation: Multiplication error. Explanation: Multiplication error. Explanation: Multi\n",
            "Output: Incorrect: 5 + 5 = 20.0? Correct: 5 + 5 = 10. Explanation:  Multiplication error\n",
            "\n",
            "Prompt: 6 * 6 = 36 but 6 / 6 = 6?\n",
            "Output: Incorrect: 6 * 6 = 36 but 6 / 6 = 6? Correct: Error evaluating expression: invalid syntax (<unknown>, line 1)\n",
            "\n",
            "Prompt: 2^3 = 6?\n",
            "Raw output from GPT-2 for 2^3 = 6?: Incorrect: 2^3 = 6? Explanation:  Multiplication error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error\n",
            "Output: Incorrect: 2^3 = 6.0? Correct: 2^3 = 8. Explanation:  Multiplication error\n",
            "\n",
            "Prompt: √16 = 5?\n",
            "Raw output from GPT-2 for √16 = 5?: Incorrect: √16 = 5? Explanation: 〚16 is 5. Explanation: Multiply by 4. Explanation: Multiply by 4. Explanation: Multiply by 4. Explanation: Multiply by 4. Explanation: Multiply by 4\n",
            "Output: Incorrect: √16 = 5.0? Correct: √16 = 4.0. Explanation: 〚16 is 5\n",
            "\n",
            "Prompt: 9 - 3 = 3?\n",
            "Raw output from GPT-2 for 9 - 3 = 3?: Incorrect: 9 - 3 = 3? Explanation:  Multiplication error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error\n",
            "Output: Incorrect: 9 - 3 = 3.0? Correct: 9 - 3 = 6. Explanation:  Multiplication error\n",
            "\n",
            "Prompt: 4 * 4 = 8?\n",
            "Raw output from GPT-2 for 4 * 4 = 8?: Incorrect: 4 * 4 = 8? Explanation:  Multiplication error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error\n",
            "Output: Incorrect: 4 * 4 = 8.0? Correct: 4 * 4 = 16. Explanation:  Multiplication error\n",
            "\n",
            "Prompt: 10 / 2 = 10?\n",
            "Raw output from GPT-2 for 10 / 2 = 10?: Incorrect: 10 / 2 = 10? Explanation:  Multiplication error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error\n",
            "Output: Incorrect: 10 / 2 = 10.0? Correct: 10 / 2 = 5.0. Explanation:  Multiplication error\n",
            "\n",
            "Prompt: 15% of 200 = 50?\n",
            "Raw output from GPT-2 for 15% of 200 = 50?: Incorrect: 15% of 200 = 50? Explanation: -------------------------15% of 200 equals 50. Explanation: 15% of 200 equals 50. Explanation: 15% of 200 equals 50. Explanation: 15% of 200 equals 50. Explanation: 15% of 200 equals 50. Explan\n",
            "Output: Incorrect: 15% of 200 = 50.0? Correct: 15% of 200 = 30.0. Explanation: -------------------------15% of 200 equals 50\n",
            "\n",
            "Prompt: 100 / 4 = 20?\n",
            "Raw output from GPT-2 for 100 / 4 = 20?: Incorrect: 100 / 4 = 20? Explanation:  Multiplication error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error\n",
            "Output: Incorrect: 100 / 4 = 20.0? Correct: 100 / 4 = 25.0. Explanation:  Multiplication error\n",
            "\n",
            "Prompt: 3 + 7 = 11?\n",
            "Raw output from GPT-2 for 3 + 7 = 11?: Incorrect: 3 + 7 = 11? Explanation:  Multiplication error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error\n",
            "Output: Incorrect: 3 + 7 = 11.0? Correct: 3 + 7 = 10. Explanation:  Multiplication error\n",
            "\n",
            "Prompt: 2 * 3 + 4 = 14?\n",
            "Raw output from GPT-2 for 2 * 3 + 4 = 14?: Incorrect: 2 * 3 + 4 = 14? Explanation:  Multiplication error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error\n",
            "Output: Incorrect: 2 * 3 + 4 = 14.0? Correct: 2 * 3 + 4 = 10. Explanation:  Multiplication error\n",
            "\n",
            "Prompt: 12 / 3 * 2 = 10?\n",
            "Raw output from GPT-2 for 12 / 3 * 2 = 10?: Incorrect: 12 / 3 * 2 = 10? Explanation:  Multiplication error. Explanation: Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Sub\n",
            "Output: Incorrect: 12 / 3 * 2 = 10.0? Correct: 12 / 3 * 2 = 8.0. Explanation:  Multiplication error\n",
            "\n",
            "Prompt: 7 * 7 = 42?\n",
            "Raw output from GPT-2 for 7 * 7 = 42?: Incorrect: 7 * 7 = 42? Explanation:  Multiplication error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error\n",
            "Output: Incorrect: 7 * 7 = 42.0? Correct: 7 * 7 = 49. Explanation:  Multiplication error\n",
            "\n",
            "Prompt: 14 - 7 = 8?\n",
            "Raw output from GPT-2 for 14 - 7 = 8?: Incorrect: 14 - 7 = 8? Explanation: ------------ Sum of squares equals 1. Explanation: Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error.\n",
            "Output: Incorrect: 14 - 7 = 8.0? Correct: 14 - 7 = 7. Explanation: ------------ Sum of squares equals 1\n",
            "\n",
            "Prompt: (3 + 2) * 2 = 12?\n",
            "Raw output from GPT-2 for (3 + 2) * 2 = 12?: Incorrect: (3 + 2) * 2 = 12? Explanation:  Multiplication error. Explanation: Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Sub\n",
            "Output: Incorrect: (3 + 2) * 2 = 12.0? Correct: (3 + 2) * 2 = 10. Explanation:  Multiplication error\n",
            "\n",
            "Prompt: 50% of 100 = 60?\n",
            "Raw output from GPT-2 for 50% of 100 = 60?: Incorrect: 50% of 100 = 60? Explanation:  50% of 100 equals 60. Explanation: 50% of 100 equals 60. Explanation: 50% of 100 equals 60. Explanation: 50% of 100 equals 60. Explanation: 50% of 100 equals 60. Explanation\n",
            "Output: Incorrect: 50% of 100 = 60.0? Correct: 50% of 100 = 50.0. Explanation:  50% of 100 equals 60\n",
            "\n",
            "Prompt: 9 + 9 = 18 then 18 / 2 = 10?\n",
            "Output: Incorrect: 9 + 9 = 18 then 18 / 2 = 10? Correct: Error evaluating expression: invalid syntax (<unknown>, line 1)\n",
            "\n",
            "Prompt: 5! = 100?\n",
            "Raw output from GPT-2 for 5! = 100?: Incorrect: 5! = 100? Explanation:  Multiplication error. Explanation: Multiplication error. Explanation: Multiplication error. Explanation: Multiplication error. Explanation: Multiplication error. Explanation: Multiplication error. Explanation: Multi\n",
            "Output: Incorrect: 5! = 100.0? Correct: 5! = 120. Explanation:  Multiplication error\n",
            "\n",
            "Prompt: 3^2 + 4^2 = 14?\n",
            "Raw output from GPT-2 for 3^2 + 4^2 = 14?: Incorrect: 3^2 + 4^2 = 14? Explanation:  Multiplication error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error. Subtraction error\n",
            "Output: Incorrect: 3^2 + 4^2 = 14.0? Correct: 3^2 + 4^2 = 25. Explanation:  Multiplication error\n",
            "\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ff642c2e8df60657d4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ff642c2e8df60657d4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import Dataset\n",
        "import gradio as gr\n",
        "import re\n",
        "import ast\n",
        "import operator as op\n",
        "\n",
        "# Define supported operators for safe evaluation\n",
        "operators = {\n",
        "    ast.Add: op.add,\n",
        "    ast.Sub: op.sub,\n",
        "    ast.Mult: op.mul,\n",
        "    ast.Div: op.truediv,\n",
        "    ast.Pow: op.pow,\n",
        "    ast.USub: op.neg\n",
        "}\n",
        "\n",
        "# Function to safely evaluate a math expression\n",
        "def evaluate_expression(expr):\n",
        "    try:\n",
        "        expr = expr.replace(\"÷\", \"/\")  # Replace ÷ with / for Python compatibility\n",
        "        expr = expr.replace(\"^\", \"**\")\n",
        "        tree = ast.parse(expr, mode='eval')\n",
        "        result = eval_node(tree.body)\n",
        "        return result, None  # Successful evaluation: return (result, None)\n",
        "    except Exception as e:\n",
        "        return None, f\"Error evaluating expression: {str(e)}\"  # Failed evaluation: return (None, error message)\n",
        "\n",
        "def eval_node(node):\n",
        "    if isinstance(node, ast.Num):\n",
        "        return node.n\n",
        "    elif isinstance(node, ast.BinOp):\n",
        "        left = eval_node(node.left)\n",
        "        right = eval_node(node.right)\n",
        "        return operators[type(node.op)](left, right)\n",
        "    elif isinstance(node, ast.UnaryOp):\n",
        "        operand = eval_node(node.operand)\n",
        "        return operators[type(node.op)](operand)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported operation\")\n",
        "\n",
        "# Function to handle factorial\n",
        "def compute_factorial(n):\n",
        "    if not isinstance(n, int) or n < 0:\n",
        "        return None\n",
        "    if n == 0:\n",
        "        return 1\n",
        "    result = 1\n",
        "    for i in range(1, n + 1):\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "# Dataset for fine-tuning GPT-2 (only for explanations)\n",
        "data = [\n",
        "    {\"input\": \"Incorrect: 8 ÷ 2(2+2) = 1?\", \"output\": \"Explanation: Evaluate parentheses first then perform division and multiplication sequentially.\"},\n",
        "    {\"input\": \"Incorrect: 5 + 5 = 20?\", \"output\": \"Explanation: Simple addition error.\"},\n",
        "    {\"input\": \"Incorrect: 6 * 6 = 36 but 6 / 6 = 6?\", \"output\": \"Explanation: A number divided by itself equals 1.\"},\n",
        "    {\"input\": \"Incorrect: 2^3 = 6?\", \"output\": \"Explanation: 2 cubed is 8.\"},\n",
        "    {\"input\": \"Incorrect: √16 = 5?\", \"output\": \"Explanation: The square root of 16 is 4.\"},\n",
        "    {\"input\": \"Incorrect: 9 - 3 = 3?\", \"output\": \"Explanation: Correct subtraction yields 6.\"},\n",
        "    {\"input\": \"Incorrect: 4 * 4 = 8?\", \"output\": \"Explanation: Multiplication error.\"},\n",
        "    {\"input\": \"Incorrect: 10 / 2 = 10?\", \"output\": \"Explanation: Division error.\"},\n",
        "    {\"input\": \"Incorrect: 15% of 200 = 50?\", \"output\": \"Explanation: 15% of 200 equals 30.\"},\n",
        "    {\"input\": \"Incorrect: 100 / 4 = 20?\", \"output\": \"Explanation: Division error.\"},\n",
        "    {\"input\": \"Incorrect: 3 + 7 = 11?\", \"output\": \"Explanation: 3 plus 7 equals 10.\"},\n",
        "    {\"input\": \"Incorrect: 2 * 3 + 4 = 14?\", \"output\": \"Explanation: Follow order of operations: multiply then add.\"},\n",
        "    {\"input\": \"Incorrect: 12 / 3 * 2 = 10?\", \"output\": \"Explanation: 12 divided by 3 is 4; 4 times 2 is 8.\"},\n",
        "    {\"input\": \"Incorrect: 7 * 7 = 42?\", \"output\": \"Explanation: Multiplication error.\"},\n",
        "    {\"input\": \"Incorrect: 14 - 7 = 8?\", \"output\": \"Explanation: Subtraction error.\"},\n",
        "    {\"input\": \"Incorrect: (3 + 2) * 2 = 12?\", \"output\": \"Explanation: Add first, then multiply.\"},\n",
        "    {\"input\": \"Incorrect: 50% of 100 = 60?\", \"output\": \"Explanation: 50% is half of 100.\"},\n",
        "    {\"input\": \"Incorrect: 9 + 9 = 18 then 18 / 2 = 10?\", \"output\": \"Explanation: Division error.\"},\n",
        "    {\"input\": \"Incorrect: 5! = 100?\", \"output\": \"Explanation: 5 factorial is 120.\"},\n",
        "    {\"input\": \"Incorrect: 3^2 + 4^2 = 14?\", \"output\": \"Explanation: 9 + 16 equals 25.\"}\n",
        "]\n",
        "\n",
        "# Combine input and output for training\n",
        "train_data = [{\"text\": f\"{item['input']} {item['output']}\"} for item in data]\n",
        "dataset = Dataset.from_list(train_data)\n",
        "print(\"Dataset created with\", len(dataset), \"examples.\")\n",
        "\n",
        "# Load GPT-2 tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "print(\"GPT-2 model loaded.\")\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True, max_length=128, padding=\"max_length\")\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=False)\n",
        "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "print(\"Dataset tokenized.\")\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=5,\n",
        "    logging_steps=1,\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.1,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# Inference function\n",
        "def correct_math(prompt):\n",
        "    # Step 1: Rule-based correction for the correct answer\n",
        "    prompt = prompt.strip()\n",
        "    match = re.match(r\"(.+?)\\s*=\\s*(\\d+\\.?\\d*)\\?\", prompt)\n",
        "    if not match:\n",
        "        return f\"Incorrect: {prompt} Correct: (unable to parse expression).\"\n",
        "\n",
        "    expr, incorrect_answer = match.groups()\n",
        "    expr = expr.strip()\n",
        "    incorrect_answer = float(incorrect_answer)\n",
        "\n",
        "    # Handle special cases (factorial, percentages, square roots)\n",
        "    if \"!\" in expr:\n",
        "        num = int(re.search(r\"(\\d+)!\", expr).group(1))\n",
        "        correct_answer = compute_factorial(num)\n",
        "        expr = f\"{num}!\"\n",
        "    elif \"% of\" in expr:\n",
        "        percentage, number = map(float, re.search(r\"(\\d+)% of (\\d+)\", expr).groups())\n",
        "        correct_answer = (percentage / 100) * number\n",
        "    elif \"√\" in expr:\n",
        "        number = float(re.search(r\"√(\\d+)\", expr).group(1))\n",
        "        correct_answer = number ** 0.5\n",
        "    else:\n",
        "        correct_answer, error = evaluate_expression(expr)\n",
        "        if error:\n",
        "            return f\"Incorrect: {prompt} Correct: {error}\"\n",
        "\n",
        "    correct_answer = round(correct_answer, 2) if isinstance(correct_answer, float) else correct_answer\n",
        "\n",
        "    # Step 2: Use GPT-2 to generate the explanation\n",
        "    model.eval()\n",
        "    full_prompt = f\"Incorrect: {prompt} Explanation: \"\n",
        "    inputs = tokenizer(full_prompt, return_tensors=\"pt\", padding=True)\n",
        "    input_ids = inputs.input_ids.to(model.device)\n",
        "    attention_mask = inputs.attention_mask.to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_new_tokens=50,\n",
        "        num_beams=4,\n",
        "        early_stopping=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f\"Raw output from GPT-2 for {prompt}: {result}\")\n",
        "\n",
        "    # Extract the explanation\n",
        "    match = re.search(r\"Explanation: (.*?)(?:\\.)\", result)\n",
        "    explanation = match.group(1) if match else \"No explanation generated.\"\n",
        "\n",
        "    # Step 3: Combine the rule-based correction with the model's explanation\n",
        "    return f\"Incorrect: {expr} = {incorrect_answer}? Correct: {expr} = {correct_answer}. Explanation: {explanation}\"\n",
        "\n",
        "# Test all prompts in the dataset\n",
        "prompts = [item[\"input\"].replace(\"Incorrect: \", \"\") for item in data]\n",
        "for prompt in prompts:\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Output: {correct_math(prompt)}\\n\")\n",
        "\n",
        "# Gradio interface\n",
        "gr.Interface(\n",
        "    fn=correct_math,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Math Correction Model\",\n",
        "    description=\"Enter an incorrect math statement (e.g., '5! = 100?') to get the correct answer and explanation.\"\n",
        ").launch()"
      ]
    }
  ]
}